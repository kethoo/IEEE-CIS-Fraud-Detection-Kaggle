{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nfrom sklearn.feature_selection import RFE\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.base import BaseEstimator, TransformerMixinfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (roc_auc_score, average_precision_score, precision_score, recall_score, classification_report, f1_score)\nimport matplotlib.pyplot as plt\n\nfrom xgboost import XGBClassifier, plot_importance\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"054166c7-82da-46fd-800c-35c9a7a2211c","_cell_guid":"67e05488-c0d3-4efd-a7f9-8e6da4d429b6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:32:31.964851Z","iopub.execute_input":"2025-04-29T10:32:31.965356Z","iopub.status.idle":"2025-04-29T10:32:31.979489Z","shell.execute_reply.started":"2025-04-29T10:32:31.965317Z","shell.execute_reply":"2025-04-29T10:32:31.978251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install dagshub\n!pip install mlflow\nimport dagshub\nimport mlflow\n\ndagshub.init(repo_owner='kechik21',repo_name='ML_HW2',mlflow=True)","metadata":{"_uuid":"42e480d7-549a-42ca-9451-6d352e1d266b","_cell_guid":"427c1e71-47cb-44ad-936f-669ee452eacc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:32:31.981247Z","iopub.execute_input":"2025-04-29T10:32:31.981661Z","iopub.status.idle":"2025-04-29T10:32:42.464882Z","shell.execute_reply.started":"2025-04-29T10:32:31.981625Z","shell.execute_reply":"2025-04-29T10:32:42.463697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training data\ntrain_tr = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\ntrain_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n\ntrain = train_tr.merge(train_id, on='TransactionID', how='left')\nprint(train_tr.shape)\nprint(train_id.shape)","metadata":{"_uuid":"29b32e11-44bb-42f7-b81f-fc2ddd689252","_cell_guid":"dbfc5bdb-e495-474c-852e-12a7786bbfe0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:32:42.467091Z","iopub.execute_input":"2025-04-29T10:32:42.467569Z","iopub.status.idle":"2025-04-29T10:33:07.295619Z","shell.execute_reply.started":"2025-04-29T10:32:42.467496Z","shell.execute_reply":"2025-04-29T10:33:07.294676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train Data Columns:\")\nprint(train.columns)","metadata":{"_uuid":"25afe7e2-4d94-4353-b0ed-24077679e14b","_cell_guid":"a577667d-e0fc-405a-9ea0-018aa1fe7890","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:07.297706Z","iopub.execute_input":"2025-04-29T10:33:07.297994Z","iopub.status.idle":"2025-04-29T10:33:07.304502Z","shell.execute_reply.started":"2025-04-29T10:33:07.297971Z","shell.execute_reply":"2025-04-29T10:33:07.303449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train.drop(['TransactionID', 'isFraud'], axis=1)\ny = train['isFraud']","metadata":{"_uuid":"3f6515cd-2ea8-48a4-8950-e151505ba6c5","_cell_guid":"b5c21c99-b3f3-451f-b560-3290d50c4325","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:07.306168Z","iopub.execute_input":"2025-04-29T10:33:07.306610Z","iopub.status.idle":"2025-04-29T10:33:08.186729Z","shell.execute_reply.started":"2025-04-29T10:33:07.306554Z","shell.execute_reply":"2025-04-29T10:33:08.185259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Differentiate categorical and numerical\ncat_coluka = ['userId','P_emaildomain','R_emaildomain','DeviceType','DeviceInfo','ProductCD','addr1', 'addr2',]\ncat_cards = ['card' + str(i) for i in range(1, 7)]\ncat_ms = ['M' + str(i) for i in range(1, 10)]\ncat_ids = ['id_' + str(i) for i in range(12, 39)]\ncat_cols = cat_coluka + cat_cards + cat_ms + cat_ids\n\nprint(\"Categorical Columns:\")\nprint(cat_cols)\nprint(\"\\nCard Columns:\")\nprint(cat_cards)\nprint(\"\\nM Columns:\")\nprint(cat_ms)\nprint(\"\\nID Columns:\")\nprint(cat_ids)\nprint(\"\\nAll Categorical Features:\")\nprint(cat_cols)\nprint(\"\\nCategorical Columns Amount:\")\nprint(len(cat_cols))\n\n\nnum_cols = [col for col in X.columns if col not in cat_cols and col != 'isFraud']\n\nprint(\"\\nNumerical Columns Amount:\")\nprint(len(num_cols))","metadata":{"_uuid":"37705dd3-2269-4c1a-b316-01cf19d2a559","_cell_guid":"6730c057-d45a-4540-bef6-6c60f7621f69","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:08.188629Z","iopub.execute_input":"2025-04-29T10:33:08.189032Z","iopub.status.idle":"2025-04-29T10:33:08.200839Z","shell.execute_reply.started":"2025-04-29T10:33:08.188997Z","shell.execute_reply":"2025-04-29T10:33:08.199744Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"class FillNa(BaseEstimator, TransformerMixin):\n    def __init__(self, num_cols, cat_cols):\n        self.num_cols = num_cols\n        self.cat_cols = cat_cols\n        self.values = {}\n\n    def fit(self, X, y=None):\n        for col in self.num_cols:\n            if col in X.columns:\n                val = X[col].median()\n                X[col] = X[col].fillna(val)\n                self.values[col] = val\n\n        for c in self.cat_cols:\n            if c in X.columns:  \n                if X[c].dtype in ['int64', 'float64']:\n                    X[c] = X[c].astype(str)\n                X[c] = X[c].fillna('NotAv')\n        return self\n\n    def transform(self, X):\n        for key, value in self.values.items():\n            if key in X.columns:\n                X[key] = X[key].fillna(value)\n\n        for c in self.cat_cols:\n            if c in X.columns:  \n                if X[c].dtype in ['int64', 'float64']:\n                    X[c] = X[c].astype(str)\n                X[c] = X[c].fillna('NotAv')\n\n        return X","metadata":{"_uuid":"aab8b04e-2c37-4a72-9a8a-add3c70a8fd2","_cell_guid":"bff61933-5f46-4c80-9020-5a0a631565d9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:08.202216Z","iopub.execute_input":"2025-04-29T10:33:08.202691Z","iopub.status.idle":"2025-04-29T10:33:08.220531Z","shell.execute_reply.started":"2025-04-29T10:33:08.202627Z","shell.execute_reply":"2025-04-29T10:33:08.219321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MissingValueDropper(BaseEstimator, TransformerMixin):\n    def __init__(self, threshold=90):\n        self.columns_to_drop = None\n        self.threshold = threshold\n\n    def fit(self, X, y=None):\n        missing_cols = [col for col in X.columns if X[col].isna().any()]\n        high_missing_cols = [\n            col for col in missing_cols \n            if (X[col].isna().mean() * 100) > self.threshold\n        ]\n        \n        self.columns_to_drop = high_missing_cols\n        print(f'Identified {len(high_missing_cols)} columns to drop')\n        return self\n\n    def transform(self, X):\n        if self.columns_to_drop is None:\n            raise ValueError('Needs Fitting !')\n        \n        return X.drop(columns=self.columns_to_drop)","metadata":{"_uuid":"31306fea-5c72-48d4-911c-5a825bae1570","_cell_guid":"89f1291c-f972-4ab4-b536-4432c969d5e4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:08.221750Z","iopub.execute_input":"2025-04-29T10:33:08.222039Z","iopub.status.idle":"2025-04-29T10:33:08.242760Z","shell.execute_reply.started":"2025-04-29T10:33:08.222017Z","shell.execute_reply":"2025-04-29T10:33:08.241677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom category_encoders import WOEEncoder\nimport pandas as pd\n\nclass CatEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, threshold=2):\n        self.threshold = threshold\n        self.binary_cols = []\n        self.multi_cols = []\n        self.encoder = None\n\n    def fit(self, X, y):\n        X = X.copy()\n        \n        for col in X.columns:\n            if X[col].dtype == 'object':\n                non_rep = X[col].nunique()\n                if non_rep <= self.threshold:\n                    self.binary_cols.append(col)\n                else:\n                    self.multi_cols.append(col)\n\n        self.encoder = WOEEncoder(cols=self.multi_cols)\n        self.encoder.fit(X[self.multi_cols], y)\n        \n        return self\n\n    def transform(self, X):\n        X = X.copy()\n        if self.multi_cols:\n            X_woe = self.encoder.transform(X[self.multi_cols])\n            X[self.multi_cols] = X_woe\n\n        if self.binary_cols:\n            X = pd.get_dummies(X, columns=self.binary_cols, drop_first=True, dtype=int)\n        \n        return X","metadata":{"_uuid":"b749c6d6-4bdb-4af8-8a5f-ad5f5e6aa7f0","_cell_guid":"6fb5d174-64ae-4654-a9e0-65b206b281ec","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:08.243759Z","iopub.execute_input":"2025-04-29T10:33:08.244098Z","iopub.status.idle":"2025-04-29T10:33:08.267024Z","shell.execute_reply.started":"2025-04-29T10:33:08.244070Z","shell.execute_reply":"2025-04-29T10:33:08.265902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HighCorrelationDropper(BaseEstimator, TransformerMixin):\n    def __init__(self, threshold=0.85):\n        self.threshold = threshold\n        self.high_corr_cols_ = None  \n        \n    def fit(self, X, y=None):\n       \n        if not isinstance(X, pd.DataFrame):\n            raise TypeError(\"Input must be a pandas DataFrame\")\n        corr_matrix = X.corr().abs()\n        upper_triangle = np.triu(corr_matrix, k=1)\n        highly_correlated = set()\n        for col in corr_matrix.columns:\n            correlated_with = corr_matrix.index[upper_triangle[:, corr_matrix.columns.get_loc(col)] > self.threshold]\n            highly_correlated.update(correlated_with)\n            \n        self.high_corr_cols_ = list(highly_correlated)\n        print(f\"Identified {len(self.high_corr_cols_)} highly correlated features to remove\")\n        \n        return self\n        \n    def transform(self, X):\n        if self.high_corr_cols_ is None:\n            raise RuntimeError(\"Need Fitting ! \")\n            \n        return X.drop(columns=self.high_corr_cols_)","metadata":{"_uuid":"6e97f505-5fb0-46a3-b390-94377daaea64","_cell_guid":"beec7d56-88e2-455c-9b6b-87d1385e29cc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:08.270867Z","iopub.execute_input":"2025-04-29T10:33:08.271173Z","iopub.status.idle":"2025-04-29T10:33:08.288520Z","shell.execute_reply.started":"2025-04-29T10:33:08.271150Z","shell.execute_reply":"2025-04-29T10:33:08.287637Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom xgboost import XGBRegressor\nimport numpy as np\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass BoostedFeatureSelector(BaseEstimator, TransformerMixin):\n    def __init__(\n        self,\n        target_feature_count=150,\n        xgb_trees=100,\n        tree_depth=6,\n        lr=0.05,\n        row_sampling=0.8,\n        col_sampling=0.8,\n        parallel_jobs=-1,\n        seed=42,\n        silent=True\n    ):\n      \n        self.target_feature_count = target_feature_count\n        self.xgb_trees = xgb_trees\n        self.tree_depth = tree_depth\n        self.lr = lr\n        self.row_sampling = row_sampling\n        self.col_sampling = col_sampling\n        self.parallel_jobs = parallel_jobs\n        self.seed = seed\n        self.silent = silent\n        self.kept_features_ = None\n        self.feature_mask_ = None\n        self.feature_ranks_ = None\n\n    def fit(self, X, y):\n        print(\"Starting feature selection...\")\n        \n        xgb_model = XGBRegressor(\n            n_estimators=self.xgb_trees,\n            max_depth=self.tree_depth,\n            learning_rate=self.lr,\n            subsample=self.row_sampling,\n            colsample_bytree=self.col_sampling,\n            n_jobs=self.parallel_jobs,\n            random_state=self.seed,\n            verbosity=0 if self.silent else 1,\n            tree_method='hist',\n            objective='reg:squarederror'\n        )\n        \n        if X.shape[1] > 200:\n            print(\" Phase 1: Fast elimination of weak features...\")\n            rough_selector = RFE(\n                estimator=xgb_model,\n                n_features_to_select=min(200, X.shape[1]),\n                step=max(1, X.shape[1] // 20)  \n            )\n            rough_selector.fit(X, y)\n            X = X.loc[:, rough_selector.support_]\n        \n        print(\" Phase 2: Fine-tuning feature set...\")\n        final_selector = RFE(\n            estimator=xgb_model,\n            n_features_to_select=self.target_feature_count,\n            step=1 \n        )\n        final_selector.fit(X, y)\n        \n        if hasattr(X, 'columns'):\n            self.kept_features_ = X.columns[final_selector.support_].tolist()\n        self.feature_mask_ = final_selector.support_\n        self.feature_ranks_ = final_selector.ranking_\n        \n        print(f\"Done! Selected {len(self.kept_features_)} features.\")\n        return self\n\n    def transform(self, X):\n       \n        if self.kept_features_ is None:\n            raise RuntimeError(\"Fit the selector first!\")\n        \n        if isinstance(X, pd.DataFrame):\n            return X[self.kept_features_]\n        return X[:, self.feature_mask_]\n\n    def get_feature_indices(self, as_indices=False):\n       \n        return np.where(self.feature_mask_)[0] if as_indices else self.feature_mask_","metadata":{"_uuid":"8bb35c49-74ab-42b9-8491-e610059718ff","_cell_guid":"b1000642-6295-4e07-b626-afa893fc2ddd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:08.289897Z","iopub.execute_input":"2025-04-29T10:33:08.291140Z","iopub.status.idle":"2025-04-29T10:33:08.324692Z","shell.execute_reply.started":"2025-04-29T10:33:08.291090Z","shell.execute_reply":"2025-04-29T10:33:08.323632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('The Classes I created are working so far')","metadata":{"_uuid":"e5d29da3-645e-41ab-bfbc-186aa7fa8fad","_cell_guid":"e2d07773-1afc-4f26-aad4-4c1d55edc049","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:08.325391Z","iopub.execute_input":"2025-04-29T10:33:08.325784Z","iopub.status.idle":"2025-04-29T10:33:08.348005Z","shell.execute_reply.started":"2025-04-29T10:33:08.325760Z","shell.execute_reply":"2025-04-29T10:33:08.346824Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"\nkva = train.drop(['TransactionID', 'isFraud'], axis=1)\ntarget = train['isFraud']\n\nX_train, X_val, y_train, y_val = train_test_split(kva,ta,test_size=0.3,stratify=target,random_state=42)","metadata":{"_uuid":"10b3f2eb-c612-4804-885d-645470817e32","_cell_guid":"a0ab6ced-2ca8-4253-9a6a-a72fb7e37436","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:08.348987Z","iopub.execute_input":"2025-04-29T10:33:08.349837Z","iopub.status.idle":"2025-04-29T10:33:12.637344Z","shell.execute_reply.started":"2025-04-29T10:33:08.349807Z","shell.execute_reply":"2025-04-29T10:33:12.636186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmlflow.set_tracking_uri('https://dagshub.com/kechik21/ML_HW2.mlflow')\nmlflow.set_experiment(\"Fraud_Detection_XGBoost\")\n\nfraud_class_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n\nfraud_pipeline = Pipeline([\n    # Data Cleaning\n    ('missing_value_handler', MissingValueDropper(threshold=90)),\n    ('data_imputer', FillNa(num_cols=num_cols, cat_cols=cat_cols)),\n    \n    # Feature Engineering\n    ('categorical_processor', CatEncoder(threshold=2)),\n    ('correlation_filter', HighCorrelationDropper(threshold=0.85)),\n    ('feature_selector', BoostedFeatureSelector(\n        target_feature_count=int(len(X_train.columns)*0.8),\n        xgb_trees=100,\n        tree_depth=6,\n        lr=0.05\n    )),\n    \n    # Model Training\n    ('fraud_classifier', XGBClassifier(\n        scale_pos_weight=fraud_class_weight,\n        eval_metric='aucpr',\n        use_label_encoder=False,\n        random_state=42\n    ))\n])\n\n\nwith mlflow.start_run(run_name=\"Production_Fraud_Model\"):\n    # Log pipeline configuration\n    mlflow.log_params({\n        \"pipeline_steps\": [name for name, _ in fraud_pipeline.steps],\n        \"class_imbalance_ratio\": fraud_class_weight,\n        \"feature_selection\": \"XGBoost_RFE\"\n    })\n    \n    print(\"Starting pipeline execution...\")\n    fraud_pipeline.fit(X_train, y_train)\n    print(\"Training completed\")\n    \n    fraud_probabilities = fraud_pipeline.predict_proba(X_val)[:, 1]\n    fraud_predictions = fraud_pipeline.predict(X_val)\n    \n    pipeline_metrics = {\n        \"validation_auc\": roc_auc_score(y_val, fraud_probabilities),\n        \"validation_ap\": average_precision_score(y_val, fraud_probabilities),\n        \"validation_f1\": f1_score(y_val, fraud_predictions),\n        \"fraud_precision\": precision_score(y_val, fraud_predictions),\n        \"fraud_recall\": recall_score(y_val, fraud_predictions)\n    }\n    \n    mlflow.log_metrics(pipeline_metrics)\n    mlflow.log_dict(\n        classification_report(y_val, fraud_predictions, output_dict=True),\n        \"classification_report.json\"\n    )\n    \n    importance_plot = plt.figure(figsize=(12, 8))\n    plot_importance(\n        fraud_pipeline.named_steps['fraud_classifier'],\n        ax=importance_plot.gca(),\n        max_num_features=20\n    )\n    plt.tight_layout()\n    mlflow.log_figure(importance_plot, \"feature_importance.png\")\n    plt.close()\n    \n    # Register model\n    mlflow.sklearn.log_model(\n        fraud_pipeline,\n        \"fraud_detection_model\",\n        registered_model_name=\"Production_Fraud_Pipeline\"\n    )\n    \n    print(f\" Pipeline deployed | Best F1: {pipeline_metrics['validation_f1']:.4f}\")","metadata":{"_uuid":"08ffdf45-a6c6-4c1c-8c49-bbf91c860b57","_cell_guid":"95f3d4aa-4a79-4785-ae72-b6d3035af38d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-29T10:33:39.038374Z","iopub.execute_input":"2025-04-29T10:33:39.040609Z","iopub.status.idle":"2025-04-29T10:38:26.976459Z","shell.execute_reply.started":"2025-04-29T10:33:39.040541Z","shell.execute_reply":"2025-04-29T10:38:26.975577Z"}},"outputs":[],"execution_count":null}]}